"""
Created on Wed Oct 5 14:28:23 2016

@author: fferreira
"""

import numpy as np
import h5py
import pandas
import matplotlib.pyplot as plt
plt.ion()
from scipy.sparse import csr_matrix


def variance(f, contributors, method="Default"):
    """ Return the error variance of specified contributors
    params:
        f : (h5py.File) : roket hdf5 file opened with h5py
        contributors : (list of string) : list of the contributors
        method : (optional, default="Default") : if "Independence", the
                    function returns ths sum of the contributors variances.
                    If "Default", it returns the variance of the contributors sum
    """
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]
    if (method == b"Default"):
        err = f[contributors[0]][:] * 0.
        for c in contributors:
            err += f[c][:]
        return np.var(P.dot(err), axis=1)  #[swap]

    elif (method == b"Independence"):
        nmodes = P.shape[0]
        v = np.zeros(nmodes)
        for c in contributors:
            v += np.var(P.dot(f[c][:]), axis=1)
        return v  #[swap]

    else:
        raise TypeError("Wrong method input")


def varianceMultiFiles(fs, frac_per_layer, contributors):
    """ Return the variance computed from the sum of contributors of roket
    files fs, ponderated by frac
    params:
        fs : (list) : list of hdf5 files opened with h5py
        frac_per_layer : (dict) : frac for each layer
        contributors : (list of string) : list of the contributors
    return:
        v : (np.array(dim=1)) : variance vector
    """
    f = fs[0]
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]
    err = f[contributors[0]][:] * 0.
    for f in fs:
        frac = frac_per_layer[f.attrs["_Param_atmos__.alt"][0]]
        for c in contributors:
            err += np.sqrt(frac) * f[c][:]

    return np.var(P.dot(err), axis=1)  #[swap]


def cumulativeSR(v, Lambda_tar):
    """ Returns the cumulative Strehl ratio over the modes from the variance
    on each mode
    params:
        v : (np.array(dim=1)) : variance vector
    return:
        s : (np.array(dim=1)) : cumulative SR
    """
    s = np.cumsum(v)
    s = np.exp(-s * (2 * np.pi / Lambda_tar)**2)

    return s


def get_cumSR(filename):
    f = h5py.File(filename, 'r')
    error_list = [
            "noise", "aliasing", "tomography", "filtered modes", "non linearity",
            "bandwidth"
    ]
    if (list(f.attrs.keys()).count("_Param_target__Lambda")):
        Lambda = f.attrs["_Param_target__Lambda"][0]
    else:
        Lambda = 1.65
    nactus = f["noise"][:].shape[0]
    niter = f["noise"][:].shape[1]
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]
    data = np.zeros((nmodes, niter))
    data2 = np.zeros(nmodes)

    for i in error_list:
        data += np.dot(P, f[i][:])
        data2 += np.var(np.dot(P, f[i][:]), axis=1)

    data = np.var(data, axis=1)
    data = np.cumsum(data[swap])
    data = np.exp(-data * (2 * np.pi / Lambda)**2)
    data2 = np.cumsum(data2[swap])
    data2 = np.exp(-data2 * (2 * np.pi / Lambda)**2)
    data *= np.exp(-f["fitting"].value)
    data2 *= np.exp(-f["fitting"].value)

    SR2 = np.ones(nmodes) * f["SR2"].value
    SR = np.ones(nmodes) * f["SR"].value

    return data, data2, SR, SR2


def get_contribution(filename, contributor):
    f = h5py.File(filename, 'r')
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]

    return np.var(np.dot(P, f[contributor][:]), axis=1)  #[swap]


def get_err_contributors(filename, contributors):
    f = h5py.File(filename, 'r')
    # Get the sum of error contributors
    err = f["noise"][:] * 0.
    for c in contributors:
        err += f[c][:]
    f.close()

    return err


def get_err(filename):
    f = h5py.File(filename, 'r')
    # Get the sum of error contributors
    err = f["noise"][:]
    err += f["aliasing"][:]
    err += f["tomography"][:]
    err += f["filtered modes"][:]
    err += f["non linearity"][:]
    err += f["bandwidth"][:]
    f.close()

    return err


def get_coverr_independence(filename):
    f = h5py.File(filename, 'r')
    # Get the sum of error contributors
    N = f["noise"][:].shape[1]
    err = f["noise"][:].dot(f["noise"][:].T)
    err += f["aliasing"][:].dot(f["aliasing"][:].T)
    err += f["tomography"][:].dot(f["tomography"][:].T)
    err += f["filtered modes"][:].dot(f["filtered modes"][:].T)
    err += f["non linearity"][:].dot(f["non linearity"][:].T)
    err += f["bandwidth"][:].dot(f["bandwidth"][:].T)
    f.close()

    return err / N


def get_coverr_independence_contributors(filename, contributors):
    f = h5py.File(filename, 'r')
    # Get the sum of error contributors
    N = f["noise"][:].shape[1]
    err = np.zeros((f["noise"][:].shape[0], f["noise"][:].shape[0]))
    for c in contributors:
        err += f[c][:].dot(f[c][:].T)

    f.close()

    return err / N


def get_pup(filename):
    f = h5py.File(filename, 'r')
    if (list(f.keys()).count("spup")):
        spup = f["spup"][:]
    else:
        indx_pup = f["indx_pup"][:]
        pup = np.zeros((f["dm_dim"].value, f["dm_dim"].value))
        pup_F = pup.flatten()
        pup_F[indx_pup] = 1.
        pup = pup_F.reshape(pup.shape)
        spup = pup[np.where(pup)[0].min():np.where(pup)[0].max() + 1,
                   np.where(pup)[1].min():np.where(pup)[1].max() + 1]

    f.close()
    return spup


def plotvsSR(data, data2, SR, SR2=None):
    plt.Figure()
    plt.plot(data, color="blue")
    plt.plot(data2, color="green")
    plt.plot(SR, color="red")
    plt.xlabel("Modes")
    plt.ylabel("Strehl ratio")
    plt.legend(["Var(X+Y)", "Var(X)+Var(Y)", "Image SR"])
    if (SR2 is not None):
        plt.plot(SR2, color="magenta")


def get_breakdown(filename):
    f = h5py.File(filename, 'r')
    P = f["P"][:]
    noise = f["noise"][:]
    trunc = f["non linearity"][:]
    bp = f["bandwidth"][:]
    tomo = f["tomography"][:]
    aliasing = f["aliasing"][:]
    filt = f["filtered modes"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]
    N = np.var(P.dot(noise), axis=1)
    S = np.var(P.dot(trunc), axis=1)
    B = np.var(P.dot(bp), axis=1)
    T = np.var(P.dot(tomo), axis=1)
    A = np.var(P.dot(aliasing), axis=1)
    F = np.var(P.dot(filt), axis=1)

    if (list(f.attrs.keys()).count("_Param_target__Lambda")):
        Lambda = f.attrs["_Param_target__Lambda"][0]
    else:
        Lambda = 1.65

    print("noise :", np.sqrt(np.sum(N)) * 1e3, " nm rms")
    print("trunc :", np.sqrt(np.sum(S)) * 1e3, " nm rms")
    print("bp :", np.sqrt(np.sum(B)) * 1e3, " nm rms")
    print("tomo :", np.sqrt(np.sum(T)) * 1e3, " nm rms")
    print("aliasing :", np.sqrt(np.sum(A)) * 1e3, " nm rms")
    print("filt :", np.sqrt(np.sum(F)) * 1e3, " nm rms")
    print("fitting :",
          np.mean(np.sqrt(f["fitting"].value / ((2 * np.pi / Lambda)**2)) * 1e3),
          " nm rms")
    return {
            "noise":
                    np.sqrt(np.sum(N)) * 1e3, "non linearity":
                            np.sqrt(np.sum(S)) * 1e3, "bandwidth":
                                    np.sqrt(np.sum(B)) * 1e3, "tomography":
                                            np.sqrt(np.sum(T)) * 1e3, "aliasing":
                                                    np.sqrt(np.sum(A)) * 1e3,
            "filtered modes":
                    np.sqrt(np.sum(F)) * 1e3, "fitting":
                            np.mean(
                                    np.sqrt(f["fitting"].value /
                                            ((2 * np.pi / Lambda)**2)) * 1e3)
    }


def plotContributions(filename):
    f = h5py.File(filename, 'r')
    P = f["P"][:]
    noise = f["noise"][:]
    trunc = f["non linearity"][:]
    bp = f["bandwidth"][:]
    tomo = f["tomography"][:]
    aliasing = f["aliasing"][:]
    filt = f["filtered modes"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes) - 2
    swap[0:2] = [nmodes - 2, nmodes - 1]

    plt.figure()
    plt.plot(np.var(noise, axis=1), color="black")
    plt.plot(np.var(trunc, axis=1), color="green")
    plt.plot(np.var(bp, axis=1), color="red")
    plt.plot(np.var(tomo, axis=1), color="blue")
    plt.plot(np.var(aliasing, axis=1), color="cyan")
    plt.plot(np.var(filt, axis=1), color="magenta")
    plt.xlabel("Actuators")
    plt.ylabel("Variance [microns^2]")
    plt.title("Variance of estimated errors on actuators")
    plt.legend([
            "noise", "WFS non-linearity", "Bandwidth", "Anisoplanatism", "Aliasing",
            "Filtered modes"
    ])

    plt.figure()
    N = np.var(P.dot(noise), axis=1)
    S = np.var(P.dot(trunc), axis=1)
    B = np.var(P.dot(bp), axis=1)
    T = np.var(P.dot(tomo), axis=1)
    A = np.var(P.dot(aliasing), axis=1)
    F = np.var(P.dot(filt), axis=1)
    plt.plot(N[swap], color="black")
    plt.plot(S[swap], color="green")
    plt.plot(B[swap], color="red")
    plt.plot(T[swap], color="blue")
    plt.plot(A[swap], color="cyan")
    plt.plot(F[swap], color="magenta")
    plt.xlabel("Modes")
    plt.ylabel("Variance [microns^2]")
    plt.yscale("log")
    plt.title("Variance of estimated errors on modal basis B")

    if (list(f.attrs.keys()).count("_Param_target__Lambda")):
        Lambda = f.attrs["_Param_target__Lambda"][0]
    else:
        Lambda = 1.65

    print("noise :",
          np.sqrt(np.sum(N)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(N) * (2 * np.pi / Lambda)**2))
    print("trunc :",
          np.sqrt(np.sum(S)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(S) * (2 * np.pi / Lambda)**2))
    print("bp :",
          np.sqrt(np.sum(B)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(B) * (2 * np.pi / Lambda)**2))
    print("tomo :",
          np.sqrt(np.sum(T)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(T) * (2 * np.pi / Lambda)**2))
    print("aliasing :",
          np.sqrt(np.sum(A)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(A) * (2 * np.pi / Lambda)**2))
    print("filt :",
          np.sqrt(np.sum(F)) * 1e3, " nm, ", "SR : ",
          np.exp(-np.sum(F) * (2 * np.pi / Lambda)**2))
    print("fitting :",
          np.sqrt(f["fitting"].value / ((2 * np.pi / Lambda)**2)) * 1e3, " nm, ",
          "SR : ", np.exp(-f["fitting"].value))
    #plt.legend(["noise","WFS non-linearity","Bandwidth","Anisoplanatism","Aliasing","Filtered modes"])


def plotCovCor(filename, maparico=None):
    f = h5py.File(filename, 'r')
    cov = f["cov"][:]
    cor = f["cor"][:]

    labels = ["noise", "non-linearity", "aliasing", "filt. modes", "bandwidht", "aniso"]
    if (maparico is None):
        maparico = "viridis"
    x = np.arange(6)
    plt.matshow(cov, cmap=maparico)
    plt.colorbar()
    plt.xticks(x, labels, rotation="vertical")
    plt.yticks(x, labels)

    plt.matshow(cor, cmap=maparico)
    plt.colorbar()
    plt.xticks(x, labels, rotation="vertical")
    plt.yticks(x, labels)
    print("Total variance : ", cov.sum(), " microns^2")


def get_IF(filename):
    f = h5py.File(filename, 'r')
    IF = csr_matrix((f["IF.data"][:], f["IF.indices"][:], f["IF.indptr"][:]))
    if (list(f.keys()).count("TT")):
        T = f["TT"][:]
    else:
        T = IF[-2:, :].toarray()
        IF = IF[:-2, :]
    f.close()
    return IF, T.T.astype(np.float32)


def get_mode(filename, n):
    f = h5py.File(filename, 'r')
    Btt = f["Btt"][:]
    IF, TT = get_IF(filename)
    dim = f["dm_dim"].value
    indx = f["indx_pup"][:]
    sc = np.zeros((dim, dim))
    sc = sc.flatten()
    mode = IF.T.dot(Btt[:-2, n])
    mode += TT.T.dot(Btt[-2:, n])
    sc[indx] = mode

    return sc.reshape((dim, dim))


def getMap(filename, covmat):
    f = h5py.File(filename, 'r')
    # nn, c'est, en gros un where(actus==valides)
    xpos = f["dm.xpos"][:]
    ypos = f["dm.ypos"][:]
    pitch = xpos[1] - xpos[0]
    nact = f.attrs["_Param_dm__nact"][0]
    x = ((xpos - xpos.min()) / pitch).astype(np.int32)
    y = ((ypos - ypos.min()) / pitch).astype(np.int32)
    nn = (x, y)

    #creation du tableau des decalages
    #xx et yy c'est les cood des actus valides
    #dx et dy c'est la matrice des differences de coordonnees, entre -nssp et +nssp
    xx = np.tile(np.arange(nact), (nact, 1))
    yy = xx.T
    dx = np.zeros((x.size, x.size), dtype=np.int32)
    dy = dx.copy()
    for k in range(x.size):
        dx[k, :] = xx[nn][k] - xx[nn]
        dy[k, :] = yy[nn][k] - yy[nn]

    # transformation des decalages en indice de tableau
    dx += (nact - 1)
    dy += (nact - 1)

    # transformation d'un couple de decalages (dx,dy) en un indice du tableau 'Map'
    Map = np.zeros((nact * 2 - 1, nact * 2 - 1)).flatten()
    div = Map.copy()
    ind = dy.flatten() + (nact * 2 - 1) * (dx.flatten())
    Cf = covmat.flatten()
    for k in range(ind.size):
        Map[ind[k]] += Cf[k]
        div[ind[k]] += 1

    div[np.where(div == 0)] = 1
    Map /= div

    return Map.reshape((nact * 2 - 1, nact * 2 - 1))


def ensquare_PSF(filename, psf, N, display=False, cmap="jet"):
    f = h5py.File(filename, 'r')
    Lambda_tar = f.attrs["_Param_target__Lambda"][0]
    RASC = 180 / np.pi * 3600.
    pixsize = Lambda_tar * 1e-6 / (psf.shape[0] * f.attrs["_Param_tel__diam"] / f.attrs[
            "_Param_geom__pupdiam"]) * RASC
    x = (np.arange(psf.shape[0]) - psf.shape[0] / 2) * pixsize / (
            Lambda_tar * 1e-6 / f.attrs["_Param_tel__diam"] * RASC)
    w = int(N * (Lambda_tar * 1e-6 / f.attrs["_Param_tel__diam"] * RASC) / pixsize)
    mid = psf.shape[0] // 2
    psfe = np.abs(psf[mid - w:mid + w, mid - w:mid + w])
    if (display):
        plt.matshow(np.log10(psfe), cmap=cmap)
        plt.colorbar()
        xt = np.linspace(0, psfe.shape[0] - 1, 6).astype(np.int32)
        yt = np.linspace(-N, N, 6).astype(np.int32)
        plt.xticks(xt, yt)
        plt.yticks(xt, yt)

    f.close()
    return psf[mid - w:mid + w, mid - w:mid + w]


def cutsPSF(filename, psf, psfs):
    f = h5py.File(filename, 'r')
    Lambda_tar = f.attrs["_Param_target__Lambda"][0]
    RASC = 180 / np.pi * 3600.
    pixsize = Lambda_tar * 1e-6 / (psf.shape[0] * f.attrs["_Param_tel__diam"] / f.attrs[
            "_Param_tel__diam"]) * RASC
    x = (np.arange(psf.shape[0]) - psf.shape[0] / 2) * pixsize / (
            Lambda_tar * 1e-6 / f.attrs["_Param_tel__diam"] * RASC)
    plt.figure()
    plt.subplot(2, 1, 1)
    plt.semilogy(x, psf[psf.shape[0] // 2, :], color="blue")
    plt.semilogy(x, psfs[psf.shape[0] // 2, :], color="red")
    plt.xlabel("X-axis angular distance [units of lambda/D]")
    plt.ylabel("Normalized intensity")
    plt.legend(["PSF exp", "PSF model"])
    plt.xlim(-20, 20)
    plt.ylim(1e-5, 1)
    plt.subplot(2, 1, 2)
    plt.semilogy(x, psf[:, psf.shape[0] // 2], color="blue")
    plt.semilogy(x, psfs[:, psf.shape[0] // 2], color="red")
    plt.xlabel("Y-axis angular distance [units of lambda/D]")
    plt.ylabel("Normalized intensity")
    plt.legend(["PSF exp", "PSF model"])
    plt.xlim(-20, 20)
    plt.ylim(1e-5, 1)
    f.close()
