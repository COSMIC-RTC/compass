"""
Created on Wed Oct 5 14:28:23 2016

@author: fferreira
"""

import numpy as np
import h5py
import pandas
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix


def variance(f, contributors, method="Default"):
    """ Return the error variance of specified contributors
    params:
        f : (h5py.File) : roket hdf5 file opened with h5py
        contributors : (list of string) : list of the contributors
        method : (optionnal, default="Default") : if "Independence", the
                    function returns ths sum of the contributors variances.
                    If "Default", it returns the variance of the contributors sum
    """
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes)-2
    swap[0:2] = [nmodes-2,nmodes-1]
    if(method == "Default"):
        err = f[contributors[0]][:] * 0.
        for c in contributors:
            err += f[c][:]
        return np.var(P.dot(err), axis=1)#[swap]

    elif(method == "Independence"):
        nmodes = P.shape[0]
        v = np.zeros(nmodes)
        for c in contributors:
            v += np.var(P.dot(f[c][:]), axis=1)
        return v#[swap]

    else:
        raise TypeError("Wrong method input")

def varianceMultiFiles(fs,frac_per_layer,contributors):
    """ Return the variance computed from the sum of contributors of roket
    files fs, ponderated by frac
    params:
        fs : (list) : list of hdf5 files opened with h5py
        frac_per_layer : (dict) : frac for each layer
        contributors : (list of string) : list of the contributors
    return:
        v : (np.array(dim=1)) : variance vector
    """
    f = fs[0]
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes)-2
    swap[0:2] = [nmodes-2,nmodes-1]
    err = f[contributors[0]][:] * 0.
    for f in fs:
        frac = frac_per_layer[f.attrs["atm.alt"][0]]
        for c in contributors:
            err += np.sqrt(frac)*f[c][:]

    return np.var(P.dot(err),axis=1)#[swap]


def cumulativeSR(v,Lambda_tar):
    """ Returns the cumulative Strehl ratio over the modes from the variance
    on each mode
    params:
        v : (np.array(dim=1)) : variance vector
    return:
        s : (np.array(dim=1)) : cumulative SR
    """
    s = np.cumsum(v)
    s = np.exp(-s*(2*np.pi/Lambda_tar)**2)

    return s


def get_cumSR(filename):
    f = h5py.File(filename)
    if(f.attrs.keys().count("target.Lambda")):
        Lambda = f.attrs["target.Lambda"][0]
    else:
        Lambda = 1.65
    nactus = f["noise"][:].shape[0]
    niter = f["noise"][:].shape[1]
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes)-2
    swap[0:2] = [nmodes-2,nmodes-1]
    data = np.zeros((nmodes,niter))
    data2 = np.zeros(nmodes)

    for i in error_list:
        data += np.dot(P,f[i][:])
        data2 += np.var(np.dot(P,f[i][:]),axis=1)

    data = np.var(data,axis=1)
    data = np.cumsum(data[swap])
    data = np.exp(-data*(2*np.pi/Lambda)**2)
    data2 = np.cumsum(data2[swap])
    data2 = np.exp(-data2*(2*np.pi/Lambda)**2)
    data *= np.exp(-f["fitting"].value)
    data2 *= np.exp(-f["fitting"].value)

    SR2 = np.ones(nmodes) * f["SR2"].value
    SR = np.ones(nmodes) * f["SR"].value

    return data, data2, SR, SR2

def get_contribution(filename,contributor):
    f=h5py.File(filename)
    P = f["P"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes)-2
    swap[0:2] = [nmodes-2,nmodes-1]


    return np.var(np.dot(P,f[contributor][:]),axis=1)#[swap]

def get_err(filename):
    f = h5py.File(filename)
    # Get the sum of error contributors
    err = f["noise"][:]
    err += f["aliasing"][:]
    err += f["tomography"][:]
    err += f["filtered modes"][:]
    err += f["non linearity"][:]
    err += f["bandwidth"][:]
    f.close()

    return err

def get_coverr_independence(filename):
    f = h5py.File(filename)
    # Get the sum of error contributors
    N = f["noise"][:].shape[1]
    err = f["noise"][:].dot(f["noise"][:].T)
    err += f["aliasing"][:].dot(f["aliasing"][:].T)
    err += f["tomography"][:].dot(f["tomography"][:].T)
    err += f["filtered modes"][:].dot(f["filtered modes"][:].T)
    err += f["non linearity"][:].dot(f["non linearity"][:].T)
    err += f["bandwidth"][:].dot(f["bandwidth"][:].T)
    f.close()

    return err / N

def plotvsSR(data,data2,SR,SR2=None):
    plt.Figure()
    plt.plot(data,color="blue")
    plt.plot(data2,color="green")
    plt.plot(SR,color="red")
    plt.xlabel("Modes")
    plt.ylabel("Strehl ratio")
    plt.legend(["Var(X+Y)","Var(X)+Var(Y)","Image SR"])
    if(SR2 is not None):
        plt.plot(SR2,color="magenta")

def plotContributions(filename):
    f=h5py.File(filename)
    P = f["P"][:]
    noise = f["noise"][:]
    trunc = f["non linearity"][:]
    bp = f["bandwidth"][:]
    tomo = f["tomography"][:]
    aliasing = f["aliasing"][:]
    filt = f["filtered modes"][:]
    nmodes = P.shape[0]
    swap = np.arange(nmodes)-2
    swap[0:2] = [nmodes-2,nmodes-1]


    plt.Figure()
    plt.plot(np.var(noise,axis=1),color="black")
    plt.plot(np.var(trunc,axis=1),color="green")
    plt.plot(np.var(bp,axis=1),color="red")
    plt.plot(np.var(tomo,axis=1),color="blue")
    plt.plot(np.var(aliasing,axis=1),color="cyan")
    plt.plot(np.var(filt,axis=1),color="magenta")
    plt.xlabel("Actuators")
    plt.ylabel("Variance [microns^2]")
    plt.title("Variance of estimated errors on actuators")
    plt.legend(["noise","WFS non-linearity","Bandwidth","Anisoplanatism","Aliasing","Filtered modes"])

    plt.Figure()
    N = np.var(P.dot(noise),axis=1)
    S = np.var(P.dot(trunc),axis=1)
    B = np.var(P.dot(bp),axis=1)
    T = np.var(P.dot(tomo),axis=1)
    A = np.var(P.dot(aliasing),axis=1)
    F = np.var(P.dot(filt),axis=1)
    plt.plot(N[swap],color="black")
    plt.plot(S[swap],color="green")
    plt.plot(B[swap],color="red")
    plt.plot(T[swap],color="blue")
    plt.plot(A[swap],color="cyan")
    plt.plot(F[swap],color="magenta")
    plt.xlabel("Modes")
    plt.ylabel("Variance [microns^2]")
    plt.yscale("log")
    plt.title("Variance of estimated errors on modal basis B")

    if(f.attrs.keys().count("target.Lambda")):
        Lambda = f.attrs["target.Lambda"][0]
    else:
        Lambda = 1.65

    print "noise :",np.sqrt(np.sum(N))*1e3," nm, ","SR : ",np.exp(-np.sum(N)*(2*np.pi/Lambda)**2)
    print "trunc :", np.sqrt(np.sum(S))*1e3," nm, ","SR : ",np.exp(-np.sum(S)*(2*np.pi/Lambda)**2)
    print "bp :", np.sqrt(np.sum(B))*1e3," nm, ","SR : ",np.exp(-np.sum(B)*(2*np.pi/Lambda)**2)
    print "tomo :", np.sqrt(np.sum(T))*1e3," nm, ","SR : ",np.exp(-np.sum(T)*(2*np.pi/Lambda)**2)
    print "aliasing :", np.sqrt(np.sum(A))*1e3," nm, ","SR : ",np.exp(-np.sum(A)*(2*np.pi/Lambda)**2)
    print "filt :", np.sqrt(np.sum(F))*1e3," nm, ","SR : ",np.exp(-np.sum(F)*(2*np.pi/Lambda)**2)
    print "fitting :", np.sqrt(f["fitting"].value/((2*np.pi/Lambda)**2))*1e3," nm, ","SR : ",np.exp(-f["fitting"].value)
    #plt.legend(["noise","WFS non-linearity","Bandwidth","Anisoplanatism","Aliasing","Filtered modes"])

def plotCovCor(filename):
    f=h5py.File(filename)
    cov = f["cov"][:]
    cor = f["cor"][:]

    labels = ["noise",
           "non-linearity",
           "aliasing",
           "filt. modes",
           "bandwidht",
           "aniso"]

    x = np.arange(6)
    plt.matshow(cov)
    plt.colorbar()
    plt.xticks(x,labels,rotation="vertical")
    plt.yticks(x,labels)

    plt.matshow(cor)
    plt.colorbar()
    plt.xticks(x,labels,rotation="vertical")
    plt.yticks(x,labels)

def get_IF(filename):
    f = h5py.File(filename)
    IF = csr_matrix((f["IF.data"][:], f["IF.indices"][:], f["IF.indptr"][:]))
    if(f.keys().count("TT")):
        T = f["TT"][:]
    else:
        T = IF[-2:,:].toarray()
        IF = IF[:-2,:]
    f.close()
    return IF, T.T.astype(np.float32)

def get_mode(filename,n):
    f=h5py.File(filename)
    Btt = f["Btt"][:]
    IF, TT= get_IF(filename)
    dim = f["dm_dim"].value
    indx = f["indx_pup"][:]
    sc = np.zeros((dim,dim))
    sc = sc.flatten()
    mode = IF.T.dot(Btt[:-2,n])
    mode += TT.T.dot(Btt[-2:,n])
    sc[indx] = mode

    return sc.reshape((dim,dim))

def getMap(filename, covmat):
    f = h5py.File(filename)
    # nn, c’est, en gros un where(actus==valides)
    xpos = f["dm.xpos"][:]
    ypos = f["dm.ypos"][:]
    pitch = xpos[1]-xpos[0]
    nact = f.attrs["nact"][0]
    x = ((xpos - xpos.min()) / pitch).astype(np.int16)
    y = ((ypos - ypos.min()) / pitch).astype(np.int16)
    nn = (x,y)

    #creation du tableau des decalages
    #xx et yy c’est les cood des actus valides
    #dx et dy c’est la matrice des différences de coordonnées, entre -nssp et +nssp
    xx = np.tile(np.arange(nact),(nact,1))[nn]
    yy = xx.T
    dx = np.zeros((nact,nact,nact))
    dy = dx.copy()
    for k in range(nact):
        dx[k,x,y] = k - xx
        dy[k,x,y] = k - yy

    # transformation des decalages en indice de tableau
    dx += nact
    dy += nact

    # transformation d'un couple de decalages (dx,dy) en un indice du tableau 'Map'
    Map = np.zeros((nact*2-1, nact*2-1)).flatten()
    div = Map.copy()
    ind = dx.flatten()+(nact*2-1)*(dy.flatten);
    for k in range(ind.size):
        Map[ind[k]] += covmat.flatten()[k]
        div[ind[k]] += 1

    div[np.where(div==0)] = 1
    Map /= div;

    return Map.reshape((nact*2-1, nact*2-1));
